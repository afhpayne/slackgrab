#!/bin/env python3

# Software Data:
soft_name = "Slackgrab"
soft_tag  = "a slackbuild tarball and binary downloader"

# Version
soft_vers = "0.4.2"

import urllib.request
import shutil
import os
import glob
import hashlib
import re

os.system("clear")
welstr = ("Welcome to " + soft_name + " version " + soft_vers + ", " + soft_tag + ".")
print("\n" + welstr)

currentwd   = os.getcwd()
build_home  = os.path.join(os.environ['HOME'], "slackstack", "")
build_prog  = glob.glob(build_home + "*-tree")
build_path  = os.path.join(str(build_prog))
build_path  = build_path.strip("[").strip("]").strip("'")

def tar_grab_func():
    infofile = glob.glob(os.path.join(currentwd, "*.info"))
    if infofile:
        infofile = infofile[0]
        os.chdir(currentwd)

        with open(infofile) as i:
            infofile = i.read()
        i.closed
        
        line_list   = []
        check_64bit = []
        url_list    = []
        md5_list    = []
        a = 0
        b = 0
        
        back_half_url = infofile.split("DOWNLOAD_x86_64=")
        for item in back_half_url[1].split():
            if "http" in item:
                url_list.append(item.strip('"'))
                a += 1
        back_half_md5 = infofile.split("MD5SUM_x86_64=")
        for item in back_half_md5[1].split():
            if len(item) > 5 and b < a:
                md5_list.append(item.strip('"'))
                b += 1
        if a != 0:
            c = 0
            for url in url_list:
                tarname = url.split('/')
                tarname = tarname[-1]
                tarname_text = tarname
                print("Downloading " + url)
                with urllib.request.urlopen(url) as response, open(tarname, 'wb') as tarname:
                    shutil.copyfileobj(response, tarname)
                    
                hasher = hashlib.md5()
                with open(tarname_text, "rb") as tarball:
                    binary = tarball.read()
                    hasher.update(binary)
                print("\n" + tarname_text + "\n")
                print("slackbuild md5sum  =", md5_list[c])
                print("actual file md5sum =", hasher.hexdigest())
                if md5_list[c] != hasher.hexdigest():
                    print("\n* * * CHECKSUMS DO NOT MATCH! * * *\n")
                else:
                    print("Checksum match :) \n")
                c += 1
        else:
            front_half_url = infofile.split("DOWNLOAD=")
            for item in front_half_url[1].split():
                if "http" in item:
                    url_list.append(item.strip('"'))
                    a += 1
            front_half_md5 = infofile.split("MD5SUM=")
            for item in front_half_md5[1].split():
                if len(item) > 5 and b < a:
                    md5_list.append(item.strip('"'))
                    b += 1
            c = 0
            for url in url_list:
                tarname = url.split('/')
                tarname = tarname[-1]
                tarname_text = tarname
                print("Downloading " + url)
                with urllib.request.urlopen(url) as response, open(tarname, 'wb') as tarname:
                    shutil.copyfileobj(response, tarname)
                    
                hasher = hashlib.md5()
                with open(tarname_text, "rb") as tarball:
                    binary = tarball.read()
                    hasher.update(binary)
                print("\n" + tarname_text + "\n")
                print("slackbuild md5sum  =", md5_list[c])
                print("actual file md5sum =", hasher.hexdigest())
                if md5_list[c] != hasher.hexdigest():
                    print("\n* * * CHECKSUMS DO NOT MATCH! * * *\n")
                else:
                    print("Checksum match :) \n")
                c += 1

            
#                    for block in iter(lambda: f.read(), b""):
#                        m.update(block)
#                        return m.hexdigest()
#                        print(md5(tarfile), "=", tarfile)


                
#         def md5(tarname):
#             m = hashlib.md5()
#             with open(tarname, "rb") as f:
#                 for block in iter(lambda: f.read(), b""):
#                     m.update(block)
#                     return m.hexdigest()
        
#         print(md5(tarname), "=", tarname)
        
#         if md5(tarname) == true_md5:
#             print("The checksums match!\n")
#         else:
#             print("WARNING: checksum mismatch!\n")


                    
            # url_64b = url_64b.split('"')[1]
            # if url_64b != '':
            #     print("\nURL =", url_64b)
            #     tar_64b = url_64b.split("/")
            #     tar_64b = (tar_64b[-1])
            #     print("\nFile name =", tar_64b)
            #     tarname = tar_64b
            #     if tar_64b != '':
            #         with urllib.request.urlopen(url_64b) as response, open(tar_64b, 'wb') as tar_64b:
            #             shutil.copyfileobj(response, tar_64b)

            

        # else:
        #     front_half_url = infofile.split("DOWNLOAD=")
        #     for item in front_half_url[1].split():
        #         if "http" in item:
        #             url_list.append(item.strip('"'))
        #             a += 1
        #     front_half_md5 = infofile.split("MD5SUM=")
        #     for item in front_half_md5[1].split():
        #         if len(item) > 5 and b < a:
        #             md5_list.append(item.strip('"'))
        #             b += 1







            
        # for line in infofile.split("DOWNLOAD_x86_64="):
        #     line_list.append(line)
        # if "http" in line_list[1]:
        #     back_half = line_list[1]
        #     back_half = back_half.split()
        #     if "MD5SUM" in back_half[1]:
        #         url_list = back_half[0].strip('"').strip()
        #         md5_list = back_half[1].strip("MD5SUM_x86_64=").strip('"').strip()
        #     else:
        #         a = 1
        #         b = 1
        #         x = 0    # 0 is the first location when script has mutiple tarballs
        #         y = 0
        #         while a == 1:
        #             if "MD5SUM" not in back_half[y]:
        #                 y += 1
        #             else:
        #                 a = 0
        #                 continue
        #         while b == 1:
        #             try:
        #                 url_check = back_half[x].strip('"').strip()
        #                 md5_check = back_half[y].strip("MD5SUM_x86_64=").strip('"').strip()
        #                 if "http" in url_check:
        #                     url_list.append(url_check)
        #                     md5_list.append(md5_check)
        #                     x += 2
        #                     y += 2
        #                 else:
        #                     b = 0
        #             except:
        #                 break
#         else:
#             front_half_url = line_list[0].split("DOWNLOAD=")
#             for item in front_half_url[1].split():
#                 if "http" in item:
#                     url_list.append(item.strip('"'))
# #            print(url_list)
#             front_half_md5 = line_list[0].split("MD5SUM=")
#             for item in front_half_md5[1].split():
#                 if len(item) > 5:
#                     md5_list.append(item.strip('"'))
# #            print(md5_list)







                    
#                url_list = front_half[1].strip('"').strip()
#                print(url_list, "HERE here")
#                exit()
#                md5_split = front_half_url[1].split("MD5SUM=")
#                print(url_list, md5_split, "HERE")
#                exit()
#                md5_list = front_half[1].strip("MD5SUM=").strip('"').strip()
        #     else:
        #         a = 1
        #         b = 1
        #         x = 0
        #         y = 0
        #         while a == 1:
        #             if "MD5SUM" not in front_half[y]:
        #                 y += 1
        #             else:
        #                 a = 0
        #                 continue
        #         while b == 1:
        #             try:
        #                 url_check = front_half[x].strip('"')
        #                 md5_check = md5_split[y].strip('"')
        #                 if "http" in url_check:
        #                     url_list.append(url_check)
        #                     md5_list.append(md5_check)
        #                     x += 2
        #                     y += 2
        #                 else:
        #                     b = 0
        #             except:
        #                 break

        # for url in url_list:
        #     print(url)
        # for md5 in md5_list:
        #     print(md5)
        # exit()

        # url_64b = url_64b.split('"')[1]
        # if url_64b != '':
        #     print("\nURL =", url_64b)
        #     tar_64b = url_64b.split("/")
        #     tar_64b = (tar_64b[-1])
        #     print("\nFile name =", tar_64b)
        #     tarname = tar_64b
        #     if tar_64b != '':
        #         with urllib.request.urlopen(url_64b) as response, open(tar_64b, 'wb') as tar_64b:
        #             shutil.copyfileobj(response, tar_64b)





            
            # else:
                # print(front_half[3])
                # url_64b = front_half[3].strip('"')
                # url_64b = url_64b.strip('DOWNLOAD="')
                # url_64b = url_64b.strip()


            
            # print(line_list[0].strip('"'))

            
#         if "http" not in line_list[7]:    # if there's nothing at location 7, there's only one binary
#             check_64bit = line_list[5]    # this is the tarball url
#             url_64b = check_64bit[17:].strip('"').strip()
#             print(url_64b)
#         else:
#             x = 1
#             y = 5    # 5 is the first location when script has mutiple tarballs
#             while x == 1:
#                 url_check = line_list[y]
#                 if "http" in url_check:
#                     url_list.append(url_check)
#                     x = 1
#                     y += 2
#                 else:
#                     x = 0
#         # print(url_list)
#         # testme = url_list.pop(0)
#         # testme = testme[17:]
#         # print(testme)
#         if not url_64b:                       # if the 64-bit line is empty, we use the 32-bit line
#             if "http" not in line_list[5]:
#                 check_64bit = line_list[3]    # this is the tarball url
#                 url_64b = check_64bit[10:].strip('"').strip()
#                 print(url_64b)
# #                print(url_64b)
#             else:
#                 x = 1
#                 y = 3    # 3 is the first location when script has mutiple tarballs
#                 while x == 1:
#                     url_check = line_list[y]
#                     if "http" in url_check:
#                         url_list.append(url_check)
#                         x = 1
#                         y += 2
#                     else:
#                         x = 0
#             print(url_list)
            
        #     print("THERES NO 32 BIT VERSION")
        # else:
        #     print("many of them")


        # check_64bit = line_list[5]
        # print(line_list)

        # print(check_64bit)
        # import re
        # text = check_64bit
        # pattern = 'http'
        # for match in re.finditer(pattern, text):
        #     s = match.start()
        #     e = match.end()
        #     print('Found "%s" at %d:%d' % (text[s:e], s, e))        
        
        # if "\n" not in check_64bit:
        #     print("ONE")
        # else:
        #     print("many")

        
        # if "http" in check_64bit:
        #     url_64b = check_64bit
        #     print(url_64b)


            
        # else:
        #     x = 1
        #     y = 5    # 5 is the first location when script has mutiple tarballs
        #     while x == 1:
        #         url_check = line_list[y]
        #         if "http" in url_check:
        #             url_list.append(url_check)
        #             x = 1
        #             y += 2
        #         else:
        #             x = 0
        # # print(url_list)
        # testme = url_list.pop(0)
        # testme = testme[17:]
        # print(testme)

        # if url_64b:
        #     print("there's a single bin")
        #     with urllib.request.urlopen(url_64b) as response, open(tar_64b, 'wb') as tar_64b:
        #         shutil.copyfileobj(response, tar_64b)
        
        # global tarname
        # global true_md5


#                 url_64b = url_64b.split('"')[1]
#                 if url_64b != '':
#                     print("\nURL =", url_64b)
#                     tar_64b = url_64b.split("/")
#                     tar_64b = (tar_64b[-1])
#                     print("\nFile name =", tar_64b)
#                     tarname = tar_64b
#                     if tar_64b != '':
#                         with urllib.request.urlopen(url_64b) as response, open(tar_64b, 'wb') as tar_64b:
#                             shutil.copyfileobj(response, tar_64b)
#                 else:
#                     for line in infofile.split("\n"):
#                         if "DOWNLOAD=" in line:
#                             url_32b = line.strip()
#                             url_32b = url_32b.split('"')[1]
#                             if url_32b != '':
#                                 print("\nURL = ", url_32b)
#                                 tar_32b = url_32b.split("/")
#                                 tar_32b = (tar_32b[-1])
#                                 print("\nFile name =", tar_32b)
#                                 tarname = tar_32b
#                                 if tar_32b != '':
#                                     with urllib.request.urlopen(url_32b) as response, open(tar_32b, 'wb') as tar_32b:
#                                         shutil.copyfileobj(response, tar_32b)

#         for line in infofile.split("\n"):
#             if "REQUIRES=" in line:
#                 depends = line.strip()
#                 depends = depends.split('"')[1]
#                 print("\nThis software requires:")
#                 for dep in depends.split(" "):
#                     print("-->", dep)

#         for line in infofile.split("\n"):
#             if "MD5SUM_x86_64=" in line:
#                 true_md5 = line.strip()
#                 true_md5 = true_md5.split('"')[1]
#                 if true_md5 != '':
#                     continue
#                 else:
#                     for line in infofile.split("\n"):
#                         if "MD5SUM=" in line:
#                             true_md5 = line.strip()
#                             true_md5 = true_md5.split('"')[1]
        
#         print("")
#         print(true_md5, "= Slackbuild MD5")
        
#         def md5(tarname):
#             m = hashlib.md5()
#             with open(tarname, "rb") as f:
#                 for block in iter(lambda: f.read(), b""):
#                     m.update(block)
#                     return m.hexdigest()
        
#         print(md5(tarname), "=", tarname)
        
#         if md5(tarname) == true_md5:
#             print("The checksums match!\n")
#         else:
#             print("WARNING: checksum mismatch!\n")

print("\nIterate all folders in [", build_path, "] ?")
yes_or_no = input("y/n: ")
if yes_or_no == "N" or yes_or_no == "n":
    print("\nOk, use current: [", os.getcwd(), "] ?")
    yes_or_no = input("y/n: ")
    if yes_or_no == "N" or yes_or_no == "n":
        exit(0)
    else:
        print("Using current directory")
        tar_grab_func()
else:
    for dir in os.scandir(os.path.join(build_path)):
        currentwd = dir
        print(currentwd)
        tar_grab_func()
